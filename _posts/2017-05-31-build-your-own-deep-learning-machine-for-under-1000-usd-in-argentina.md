---
layout: post
title: "Build Your Own Deep Learning Machine For Under 1000USD In Argentina"
date: 2017-05-31
---

Hace un tiempo terminé el curso de [Neural Networks de Hinton](https://es.coursera.org/learn/neural-networks) y aprovechando que estoy con más tiempo libre desde que me recibí a fines del año pasado decidí que finalmente este era un buen momento para subirme al hype train y empezar a entrenar mis propias redes neuronales profundas. El curso me pareció excelente y se lo recomiendo a cualquiera que este interesado en Deep Learning y no sabe por donde empezar, los assignments son en MATLAB/Octave y afortunadamente no tuve problemas para correr los algoritmos con la notebook que tenía en ese momento. Sin embargo, en la práctica si queremos entrenar redes profundas y no morir de aburrimiento esperando a que terminen vamos a necesitar hardware específico, en particular una buena placa de video.

Por ese motivo e influenciado por este [artículo](https://www.oreilly.com/learning/build-a-super-fast-deep-learning-machine-for-under-1000) y [este otro de Canadá](https://medium.com/towards-data-science/build-a-deep-learning-pc-for-1-000-cad-f3c5f26ba134), me decidi por investigar que tan factible sería **armar una máquina super rápida para Deep Learning en Argentina por menos de 1000 dólares**. Argentina es un país muy inestable en cuanto a precios con las subidas y bajadas constantes de la cotización del dólar, y más en el área de electrónica. Sin embargo descubrí que existen lugares en donde el hardware se consigue a precios razonables, donde razonable quiere decir algo así como un 20 o 30% más que lo que lo pagaríamos en Amazon. El análisis me llevó unos días, no fue fácil encontrar una buena combinación que cueste menos de 1000 dólares y sin tener que resignar partes importantes así que me pareció una buena idea resumir los resultados acá para que alguien más los pueda aprovechar y no tener que empezar de cero si quiere armar su propia máquina.

Bueno, a continuación voy a explicar que componentes que elegí y por qué los elegí pero antes viene un disclaimer: la máquina tiene una GPU muy buena pero no es una pc gamer, de hecho, el sistema operativo que usa es Linux Ubuntu y no posee monitor sino que la accedo por ssh. Tampoco está pensada para otros contextos en los que se necesite hacer uso intensivo del CPU, *esto incluye entrenar algoritmos de Machine Learning*. Ahora si, la máquina...

# CPU

La recomendación que leí es usar dos threads por cada GPU. El microprocesador que seleccioné tiene 2 cores y 4 threads así que estaría cubierto por ese lado ya que sólo pienso usar una GPU. Y acá viene un tema que me llevo un buen tiempo decidir y que por otro lado me pareció super interesante: la elección del micro **Pentium g4560** como procesador. Yo trabajo como data scientist y algunas de las tareas que realizo a diario requieren un gran poder de computo con lo cual en mi trabajo cuento con una procesador multicore y con suficiente memoria para cargar datasets que pesan varios Gigabytes. Ahora bien, si quisiera usar ésta máquina para entrenar algoritmos de Machine Learning (los cuales se entrenan en la CPU), estaría relativamente bien aunque a la hora de tunear los hiperparámetros de los modelos sería mucho mas feliz con un i5 de 4 cores en lugar de 2 cores y 4 threads. Incluso seria mucho mas sensato incluir un i7 con 4 cores y 8 threads. El problema es que este tipo de procesadores **cuestan entre 3 y 6 veces mas** que el Pentium g4560. Estuve bastante tiempo analizando este dilema y llegue a la conclusión de que lo mejor era ir por el Pentium y la razón es la siguiente:
> la principal tarea de la máquina va a ser entrenar redes profundas y por ese motivo estoy invirtiendo aproximadamente el 50% del presupuesto en la GPU que es donde se va a realizar el entrenamiento.
Mucha gente a la que le mostré la configuración final (y otras similares) se sorprendían por la elección del CPU, y de hecho, a mi también me costó entender por qué era una buena elección. Podríamos decir que *la verdadera “unidad central de proceso” en esta máquina es la GPU*, de hecho, me veo obligado a comprar una CPU porque no existe la opción de armar una pc que no tenga una (al menos yo no la conozco :), con lo cual mi tarea fue elegír el micro más barato tratando de evita introducir un cuello de botella a la configuración. Otra opción factible podría ser un i3 7100 que tiene la misma cantidad de cores y threads pero con un clock de 3.9Ghz en lugar de 3.5Ghz del g4560. El problema es que el i3 cuesta el doble con lo cual no me pareció razonable gastar el doble por un incremento en el rendimiento del CPU de a lo sumo un 11% y mas teniendo en cuenta el objetivo que mencioné. Con el tiempo me voy a dar cuenta si fue una buena elección... según [este blog](http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/) el clock rate del procesador es prácticamente irrelevante mientras sea mayor a 2Ghz y en el caso del g4560 es casí el doble que eso, y las caches del micro tampoco importan.
Para alguien con un presupuesto más grande o que quiera/necesite usar la misma máquina para entrenar modelos de Machine Learning le recomendaría ir por un i5 7500 o un i7 7700,  y sus respectivas versiones con una K al final si están dispuestos a overclockearlos (hay que tener en cuenta que el mother tiene que soportar el overclocking y por lo tanto va a ser más caro).

# GPU

La GPU es la parte mas importante de la configuración y por lo tanto vale la pena invertir una buena parte del presupuesto acá. Las librerías usadas para entrenar redes profundas como Theano y TensorFlow están optimizadas para correr en la GPU. Existe la opción de correr los algoritmos en la CPU pero el decremento en la performance es muy grande. Las tarjetas gráficas en la actualidad cuentan con miles de cores y están diseñadas para realizar multiplicaciones de matrices de manera eficiente y esto es lo que explotan las librerías de Deep Learning. Existen muchas opciones en cuanto al chipset de la tarjeta y la marca. Básicamente tenemos dos opciones de chipsets, están los de Nvidia y los de AMD. Hoy en día la comunidad de Deep Learning usa los chipsets de Nvidia principalmente y esto es así gracias en parte a que existe CUDA que es una librería que permite a los desarrolladores ejecutar código (una variante de C) en la GPU. Existen wrappers para Python, Fortran y Java además de las variantes de C y C++.

Nvidia posee una gran variedad de placas que pueden utilizarse pero en el área las mas recomendadas y que están al alcance del bolsillo para alguien que vive por estas latitudes son las de la serie GTX 1000. En particular las GTX 1060, GTX 1070, GTX 1080 y GTX 1080ti. Todas las placas están basadas en la última arquitectura de Nvidia denominada Pascal y la diferencia principal entre estas placas es la cantidad de RAM que tienen. La 1060 viene en dos versiones una de 3GB y una de 6GB, la 1070 y la 1080 vienen con 8GB y finalmente la 1080ti con 11GB. Teóricamente la GTX 1060 de 6GB es una excelente placa para comenzar con Deep Learning, sobre todo para los que no se quieren meter seriamente o que disponen de un presupuesto ajustado. Por otro lado, la GTX 1070 es ideal para la mayoría de los casos restantes ya que al igual que la GTX 1080 posee 8GB de RAM pero cuestan entre un 30 y un 40% menos. [Acá](http://timdettmers.com/2017/04/09/which-gpu-for-deep-learning/) hay una explicación mucho mas detallada sobre las diferentes placas y sobre que cosas tener en cuenta a la hora de elegír una. Yo finalmente me decidí por la 1070, podría haber seleccionado la 1060 de 6GB pero no quise arriesgarme a que en el futuro surjan problemas relacionados con la falta de RAM. En cuanto a los precios, en Argentina la 1070 es entre un 50 y un 60% mas cara que la 1060 dependiendo la marca, lo cual es una diferencia muy grande y quizás a muchos les parezca mas conveniente empezar con una 1060 sobre todo si el factor económico es importante. En ese caso el costo total se reduce considerablemente dando lugar para agregar otros componentes, como más RAM, disco, un mejor microprocesador, etc. La placa seleccionada fue la **Zotac GTX 1070 Mini** que conseguí a un precio muy bueno comparado con otras marcas.

# RAM

La GPU que elegí cuenta con 8GB de RAM, con lo cual según leí debería usar al menos 8GB de RAM para el CPU. En el pasado tuve problemas para trabajar con datos grandes que no entraban en la RAM y encontré maneras de sobrellevarlo (tomar muestras aleatorias, procesar los datos por batches, usar memmap de Numpy para que múltiples procesos compartan datos en la RAM, comprarme una consola para jugar mientras entrenan los algoritmos sin multithreading, etc.) pero creo que no vale la pena repetir ese error con lo cual decidí equipar la máquina con 16GB de memoria y elegí una mother con 4 slots que soporta hasta 64GB de RAM DDR4. Las memorias que elegí tienen un clock rate de 2400Mhz que es la máxima velocidad que soporta la mother. Decidí comprar dos de 8GB en lugar de una de 16GB porque en teoría el controlador [puede buscar los datos mas rápido gracias al dual channel] (http://www.tomshardware.com/answers/id-2801830/memory-upgrade-1x16gb-2x8gb.html) y me quedaron dos slots extras por si en el futuro quiero agregar mas memoria :).
En este [artículo](http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/) recomiendan usar **asynchronous mini-batch allocation** para evitar cuellos de botella relacionados a lo que tardan en transmitirse los datos de la RAM de la CPU a la RAM de la GPU. En resumen, el tiempo que tarda la comúnmente la GPU en procesar un mini-batch es mayor al tiempo que tarda cualquier memoria por mas lenta que sea en transmitir los datos del proximo mini-batch, con lo cual la velocidad de la RAM y el tamaño de la cache del CPU son irrelevantes mientras que la cantidad de RAM del CPU sea mayor o igual que la del GPU. Teniendo en cuenta esto, podría haber elegído una memoria a 2133Mhz pero no había mucha diferencia en los precios y tampoco encontré muchas opciones.

# Motherboard

La elección del motherboard (a.k.a. mobo) fue algo complicada ya que en general hay mucha variedad de precios y prestaciones. Al momento de elegírla me enfoque en que tuviera soporte para memorias DDR4 a 2400Mhz, que soporte hasta 64GB de RAM, que sea compatibles con los nuevos procesadores Kabylake sin necesidad de actualizar el BIOS y que sea barato (un poco mucho je). Lo mejor que encontré fue una **Gigabyte GA-B250M-DS3H** a un precio muy razonable. Existen mejores opciones pero que cuestan el doble o más, con soporte para memorias DDR4 a 3000Mhz o más y que incluyen la posibilidad de overclockear el procesador, pero eso es algo que no tenia pensado hacer por el momento. Otro punto importante es la cantidad de slots PCIe si tenemos intenciones de usar más de una GPU, ésta mother sólo incluye un slot PCIe x16 (que es la interfaz de la placa de video) pero igualmente sólo pensaba usar una placa y no creo que vaya a requerir otra en el corto/mediano plazo. Llegado el caso lo lamentaré pero como primer configuración para meterse en el área me parece bien.

# Disco/SSD

Mi idea es usar las redes para reconocimiento en imágenes y probablemente tareas de NLP en texto pero a priori no sé el tamaño de los datasets que voy a usar. Decidí usar una **SSD Sandisk de 120Gb** para que los datasets se lean rápido y no tener el problema de que la velocidad de lectura de los datos se vuelva un cuello de botella. Los datasets viejos que no este usando los pienso guardar en un disco externo de 1TB que tengo pero posiblemente en el futuro voy a necesitar un disco de 1 tera o dos para ir guardando cosas ahi y tener un backup de mis archivos. Actualmente los discos están muy baratos, un disco de 1TB Wester Digital Caviar Blue se consigue por menos de mil pesos y es bastante difícil llenarlo.

# Fuente

La fuente que elegí es una **EVGA de 500 watts**. Se trata de una fuente 80 plus certificada y en general son fuentes muy recomendadas por su relación calidad y precio. En cuanto a la capacidad de la fuente, el cálculo de consumo de esta configuración en [pcpartpicker](https://pcpartpicker.com/list/NLN6Z8) da 284 watts, con lo cual estaría dejando 216 watts extras para picos de energía y futuros componentes que pueda agregar. Por ejemplo, si en el futuro agregamos 2 memorias más de 8gb y un disco de 1TB a la configuración el calculo de consumo sube a [314 watts](https://pcpartpicker.com/list/LFvjkT), con lo que seguiríamos teniendo unos 186 watts extra.
También podría haber utilizado una fuente de 430 watts. La diferencia en plata no era significativa pero al margen no me pareció una buena idea arriesgarme en este caso, tengo entendido que los problemas con las fuentes son un verdadero dolor de cabeza.

# Gabinete

Finalmente, habiendo seleccionado todos los demas componentes tuve que elegír un gabinete y la verdad que esto me llevó más tiempo del esperado. No hay mucho de lo que tengamos que preocuparnos, más que asegurarnos de que la placa de video y el mother que elijamos entren en el espacio que nos provee el gabinete. Después está la cuestión estética y eso ya es una cuestión personal, existen modelos para todos los gustos. Hasta último momento estuve evaluando varios modelos, algunos más caros como el NZXT s340, Corsair Carbide 400c, Phanteks Eclipse P400, Phanteks Enthoo Pro M y otros más economicos, como Corsair Carbide Spec 03, Corsair Carbide R100 y Thermaltake Core V1 (la caja, la caja!). Finalmente me decidí por el gabinete **Corsair Carbide 100R** ya que los gabinetes junto con las fuentes y las motherboards están mucho más caros que los demas componentes y no tenia sentido gastar mas de un 10% del presupuesto en el gabinete habiendo bajado tanto el costo en otros componentes más importantes.
El gabinete soporta GPUs de hasta 414mm en los slots superiores y 275mm en los inferiores. La placa de video que elegí tiene 210mm de largo así que no va a habler problemas para montarla. El mother es Mini-ATX, el cual también soporta este gabinete.
